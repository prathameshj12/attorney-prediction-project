{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "089a6691-91d1-477b-b3a6-a5450c93c71c",
   "metadata": {},
   "source": [
    "# **Predictive Modeling for Attorney Involvement in Claims**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf421b35-80c6-43e0-8cf3-c0a18d4659e0",
   "metadata": {},
   "source": [
    "## **1. Data Loading and Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faff7bc5-ce70-46bb-9ca5-96f27004ff6b",
   "metadata": {},
   "source": [
    "#### **Importing Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a834d079-5fa5-4164-9f5c-9b9ee2ab7022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prathamesh\\AppData\\Local\\Temp\\ipykernel_59272\\3106237401.py:6: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from IPython.core.display import display, HTML\n",
    "import missingno as msno\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder  \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "479bfeaa-bce6-46e1-a644-ec8abcd71452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Style Tables using Pandas\n",
    "\n",
    "# HTML Styling for Notebook Headers\n",
    "def display_header(text):\n",
    "    display(HTML(f'<h3 style=\"color:#808080; text-align:left;\">{text}</h3>'))\n",
    "\n",
    "def display_subheader(text):\n",
    "    display(HTML(f'<h4 style=\"color:#808080; text-align:left;\">{text}</h4>'))\n",
    "\n",
    "# Global function for styling tables \n",
    "def style_table(df):\n",
    "    return df.style.set_properties(**{\n",
    "        'text-align': 'left',\n",
    "        'border': '1px solid black'\n",
    "    }).set_table_styles([{\n",
    "        'selector': 'th',\n",
    "        'props': [('background-color', '#2a3f5f'), ('color', 'white'), ('font-weight', 'bold')]\n",
    "    }])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63efe8aa-42a7-46b4-9ba2-ada53e8c8f00",
   "metadata": {},
   "source": [
    "#### **Loading Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e807a7-0b8e-4a7c-8942-8bca13ab1892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:#808080; text-align:left;\">Dataset uploaded successfully.</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = r\"Sample_Dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "display_subheader(\"Dataset uploaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5073e7a4-db7e-498c-a156-0fa71f9e9001",
   "metadata": {},
   "source": [
    "#### **Dataset Structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ec559bdb-c297-4667-afcb-0ab6c6fba9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display Dataset Overview (First 5 Rows)\n",
    "# display_header(\"Dataset Overview: \")\n",
    "# display(style_table(df.head()))  # Display first 5 rows\n",
    "\n",
    "# # Display Dataset Information in Styled Table\n",
    "# display_header(\"Dataset Information: \")\n",
    "# info_df = pd.DataFrame({\n",
    "#     \"Columns\": df.columns,  # Show only column names\n",
    "#     \"Non-Null Count\": df.notnull().sum(),\n",
    "#     \"Data Type\": df.dtypes.astype(str)\n",
    "\n",
    "# }).reset_index(drop=True)  # Remove the index\n",
    "# display(style_table(info_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "81ae0b4e-1544-492f-9e67-099ad9907588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5 style='color: Gray;'> Dataset Shape : 1340 rows, 13 columns</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Dataset Shape\n",
    "display(HTML(f\"<h5 style='color: Gray;'> Dataset Shape : {df.shape[0]} rows, {df.shape[1]} columns</h5>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfcfe9-f5a2-4d09-9738-ab5795bacc4b",
   "metadata": {},
   "source": [
    "#### **Identifying Missing and Duplicate Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "339e9b9f-42b1-4a6f-bb4b-4b4e779e5f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:#808080; text-align:left;\">Missing Values : </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Missing Values\n",
    "display_subheader(\"Missing Values : \")\n",
    "missing_df = pd.DataFrame({\"Columns\": df.columns, \"Missing Values\": df.isnull().sum(), \"Percentage\": (df.isnull().sum() / len(df)) * 100}).reset_index(drop=True)  # Remove the index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "88de7c2b-a1e0-4d6a-88e5-936151b9c8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:#808080; text-align:left;\">Duplicate Rows: 0</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Duplicate Rows\n",
    "display_subheader(f\"Duplicate Rows: {df.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a43fce-bb50-42af-8b1c-9daf9d21195a",
   "metadata": {},
   "source": [
    "#### **Basic Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "814635dc-6f63-49a7-90b5-555ae3489e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:#808080; text-align:left;\">Descriptive Statistics : </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Descriptive Statistics\n",
    "display_subheader(\"Descriptive Statistics : \")\n",
    "\n",
    "desc_stats = df.describe().transpose().reset_index()\n",
    "desc_stats.rename(columns={\"index\": \"Columns\"}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8c85e2cb-e39a-4fd1-bcd3-551832a043de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:#808080; text-align:left;\">Categorical Variable Summary : </h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Unique Value Counts for Categorical Features\n",
    "display_subheader(\"Categorical Variable Summary : \")\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "cat_summary = pd.DataFrame({\n",
    "    \"Columns\": categorical_cols,\n",
    "    \"Unique Values\": [df[col].nunique() for col in categorical_cols],\n",
    "    \"Most Frequent Value\": [df[col].mode()[0] for col in categorical_cols]\n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3504f0-859d-490a-8bc4-44f1c5ab258d",
   "metadata": {},
   "source": [
    "## **2. Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa6a3d3-91c5-4404-8703-12cb91512bf9",
   "metadata": {},
   "source": [
    "#### **Understanding the Target Variable (ATTORNEY)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d72ff2-c98a-4cc2-a903-655c50058630",
   "metadata": {},
   "source": [
    "**Distribution Plot of ATTORNEY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9c9c9681-e681-4a1c-8ea1-a541f67e2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualizing the distribution of the target variable\n",
    "# plt.figure(figsize=(6,4))\n",
    "# sns.countplot(x=df['ATTORNEY'], palette=[\"#1E88E5\", \"#D32F2F\"])\n",
    "# plt.xlabel(\"Attorney Involvement (0 = No, 1 = Yes)\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.title(\"Distribution of Attorney Involvement in Claims\")\n",
    "# plt.xticks(ticks=[0,1], labels=[\"No Attorney\", \"Attorney\"])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ccce80-ece2-452a-9272-69eef898bc87",
   "metadata": {},
   "source": [
    "**Pie Chart for Proportion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "85b2bc33-3293-468f-81e6-b10c8438b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pie Chart for Attorney vs. No Attorney cases with Legend\n",
    "# plt.figure(figsize=(6,6))\n",
    "# colors = [\"#1E88E5\", \"#D32F2F\"]\n",
    "# labels = [\"No Attorney\", \"Attorney\"]\n",
    "\n",
    "# # Create pie chart\n",
    "# wedges, texts, autotexts = plt.pie(\n",
    "#     df['ATTORNEY'].value_counts(), \n",
    "#     autopct='%1.1f%%', \n",
    "#     startangle=90, \n",
    "#     colors=colors, \n",
    "#     labels=labels\n",
    "# )\n",
    "\n",
    "# # Add legend\n",
    "# plt.legend(wedges, labels, title=\"Claim Status\", loc=\"upper right\", bbox_to_anchor=(1.3, 0.9))\n",
    "\n",
    "# plt.ylabel('')\n",
    "# plt.title(\"Proportion of Claims with Attorney Involvement\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78603b0e-52ae-46b5-ae98-30a4c0748435",
   "metadata": {},
   "source": [
    "#### **Univariate Analysis - Categorical Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f86d0c-08f4-4281-b835-17e17c836256",
   "metadata": {},
   "source": [
    "**Bar Chart for Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4669abe-4e73-4bbe-a622-2b76f31ae313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Improved Layout for Categorical Features\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "# axes = axes.flatten()  \n",
    "\n",
    "# categorical_cols = []\n",
    "\n",
    "# for i, col in enumerate(categorical_cols):\n",
    "#     sns.countplot(x=df[col], ax=axes[i], palette=\"muted\")\n",
    "#     axes[i].set_title(f\"Distribution of {col}\")\n",
    "#     axes[i].set_xlabel(col)\n",
    "#     axes[i].set_ylabel(\"Count\")\n",
    "#     axes[i].tick_params(axis='x', rotation=45)  # Rotate labels for better visibility\n",
    "\n",
    "# # Hide the last subplot if unused\n",
    "# if len(categorical_cols) < len(axes):\n",
    "#     fig.delaxes(axes[-1])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276729f-1634-4d66-8202-3898c4719b53",
   "metadata": {},
   "source": [
    "#### **Univariate Analysis - Numerical Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dd6fae-5afb-44ea-acf1-754c00fc3c01",
   "metadata": {},
   "source": [
    "**Histograms & KDE Plots for Numerical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9aff12-d408-4847-a25a-05269a566a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identifying Numerical Columns (Excluding Target Variable)\n",
    "# numerical_cols = []\n",
    "\n",
    "# # Plot Histograms Only\n",
    "# display_header(\"Histograms of Numerical Features\")\n",
    "\n",
    "# fig, axes = plt.subplots(3, 3, figsize=(15, 12))  # 3x3 grid layout for clear visibility\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for i, col in enumerate(numerical_cols):\n",
    "#     sns.histplot(df[col], bins=30, ax=axes[i], color=\"#1E88E5\")\n",
    "#     axes[i].set_title(f\"Histogram of {col}\")\n",
    "#     axes[i].set_xlabel(col)\n",
    "#     axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "# for j in range(i+1, len(axes)):\n",
    "#     fig.delaxes(axes[j])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8a0ff4de-5711-4e08-91ab-4c6ebe0bed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot KDE Plots \n",
    "# display_header(\"KDE Plots of Numerical Features\")\n",
    "\n",
    "# fig, axes = plt.subplots(3, 3, figsize=(15, 12))  # 3x3 grid layout for clear visibility\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for i, col in enumerate(numerical_cols):\n",
    "#     sns.kdeplot(df[col], fill=True, ax=axes[i], color=\"#D32F2F\")\n",
    "#     axes[i].set_title(f\"KDE Plot of {col}\")\n",
    "#     axes[i].set_xlabel(col)\n",
    "#     axes[i].set_ylabel(\"Density\")\n",
    "\n",
    "# # Hide empty plots if fewer than 9 numerical columns\n",
    "# for j in range(i+1, len(axes)):\n",
    "#     fig.delaxes(axes[j])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf97a63-daab-466f-9841-62616e06ffb8",
   "metadata": {},
   "source": [
    "#### **Missing & Null Values Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4078ab6-f188-4a0f-9aec-689efbee1dcc",
   "metadata": {},
   "source": [
    "**Bar Chart for Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c6650759-97c1-4826-aab0-0084e258d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display Missing Values Bar Chart\n",
    "# missing_count = df.isnull().sum()\n",
    "# missing_count = missing_count[missing_count > 0].sort_values(ascending=False)\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# sns.barplot(x=missing_count.index, y=missing_count.values, palette=\"Reds\")\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.ylabel(\"Missing Values Count\")\n",
    "# plt.xlabel(\"Columns\")\n",
    "# plt.title(\"Missing Values Per Column\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dadb8ab-3390-499c-858d-7b88b7703522",
   "metadata": {},
   "source": [
    "#### **Bivariate Analysis (Analyzing Relationships Between Features & ATTORNEY)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ed48a-c3ec-48a1-836a-029e2620f75d",
   "metadata": {},
   "source": [
    "**Categorical Features vs. ATTORNEY**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b32dc9b-78b7-4a73-bf88-51951dea125c",
   "metadata": {},
   "source": [
    "**Grouped Bar Chart for Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d3be16-e1f5-4b2d-85d0-edbd9fc53527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define Categorical Features\n",
    "# categorical_cols = []\n",
    "\n",
    "# # Adjust layout for better spacing\n",
    "# display_header(\"Categorical Features vs. Attorney Involvement\")\n",
    "\n",
    "# fig, axes = plt.subplots(3, 1, figsize=(10, 15))  # 3-row layout for better spacing\n",
    "\n",
    "# for i, col in enumerate(categorical_cols):\n",
    "#     sns.countplot(x=df[col], hue=df[\"ATTORNEY\"], palette=\"muted\", ax=axes[i])\n",
    "#     axes[i].set_title(f\"{col} vs. Attorney Involvement\", fontsize=14)\n",
    "#     axes[i].set_xlabel(col, fontsize=12)\n",
    "#     axes[i].set_ylabel(\"Count\", fontsize=12)\n",
    "#     axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547b545-559e-40a7-b3ee-f5e090f483c9",
   "metadata": {},
   "source": [
    "**Stacked Bar Chart for Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6ba2b806-fdab-4f23-9a1a-1c68cb322698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adjust layout for better spacing\n",
    "# display_header(\"Stacked Bar Chart: Categorical Features vs. Attorney Involvement\")\n",
    "\n",
    "# fig, axes = plt.subplots(3, 1, figsize=(10, 15))  # 3-row layout for better visibility\n",
    "\n",
    "# for i, col in enumerate(categorical_cols):\n",
    "#     cross_tab = pd.crosstab(df[col], df[\"ATTORNEY\"], normalize=\"index\") * 100\n",
    "#     cross_tab.plot(kind=\"bar\", stacked=True, colormap=\"Paired\", ax=axes[i])\n",
    "#     axes[i].set_title(f\"{col} vs. Attorney Involvement (Stacked)\", fontsize=14)\n",
    "#     axes[i].set_xlabel(col, fontsize=12)\n",
    "#     axes[i].set_ylabel(\"Percentage (%)\", fontsize=12)\n",
    "#     axes[i].legend(title=\"Attorney\", labels=[\"No Attorney\", \"Attorney\"])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7357ec0e-d420-4ffb-8444-1dbc7a4c8779",
   "metadata": {},
   "source": [
    "**Bivariate Analysis (Numerical Features vs. ATTORNEY)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27918f32-d8be-42d8-a3a2-cb170fbfdefe",
   "metadata": {},
   "source": [
    "**Boxplots for Numerical Features vs. ATTORNEY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d777ee-6230-4cf3-8f36-688f2095350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define Numerical Columns (Excluding Categorical & Target Variable)\n",
    "# numerical_cols = []\n",
    "\n",
    "# # Boxplots for Numerical Features\n",
    "# display_header(\"Boxplots: Numerical Features vs. Attorney Involvement\")\n",
    "\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(14, 10))  # 2x2 grid for clear visualization\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for i, col in enumerate(numerical_cols):\n",
    "#     sns.boxplot(x=df[\"ATTORNEY\"], y=df[col], palette=\"coolwarm\", ax=axes[i])\n",
    "#     axes[i].set_title(f\"{col} vs. Attorney Involvement\", fontsize=14)\n",
    "#     axes[i].set_xlabel(\"Attorney Involvement (0 = No, 1 = Yes)\")\n",
    "#     axes[i].set_ylabel(col)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b717f-db51-4289-839d-5f27c17f21bc",
   "metadata": {},
   "source": [
    "**Violin Plots for Numerical Features vs. ATTORNEY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2b84f27d-707b-405a-90e0-3c8fb2fb2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Violin Plots for Numerical Features\n",
    "# display_header(\"Violin Plots: Numerical Features vs. Attorney Involvement\")\n",
    "\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(14, 10))  # 2x2 layout for better spacing\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for i, col in enumerate(numerical_cols):\n",
    "#     sns.violinplot(x=df[\"ATTORNEY\"], y=df[col], palette=\"muted\", ax=axes[i])\n",
    "#     axes[i].set_title(f\"{col} vs. Attorney Involvement\", fontsize=14)\n",
    "#     axes[i].set_xlabel(\"Attorney Involvement (0 = No, 1 = Yes)\")\n",
    "#     axes[i].set_ylabel(col)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae59ad-0486-423b-891e-a73c825cbf3a",
   "metadata": {},
   "source": [
    "#### **Correlation Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b7e84e-e2bc-43af-92fd-19946edff084",
   "metadata": {},
   "source": [
    "**Correlation Heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b04eb2e3-03a4-44f2-b2b8-d368b7b8c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Selecting Only Numerical Columns (Excluding Identifier Columns)\n",
    "# numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# # Remove 'CASENUM' from the list (if present)\n",
    "# if 'CASENUM' in numerical_columns:\n",
    "#     numerical_columns.remove('CASENUM')\n",
    "\n",
    "# # Compute Correlation Matrix\n",
    "# corr_matrix = df[numerical_columns].corr()\n",
    "\n",
    "# plt.figure(figsize=(10,6))\n",
    "# sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "# plt.title(\"Correlation Heatmap\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56018db6-7f2d-451b-81ee-35ef2efee751",
   "metadata": {},
   "source": [
    "**Pairplot for Numerical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ee254-2b05-4c44-822a-6e02d6264f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Selecting Key Numerical Features for Pairplot\n",
    "# pairplot_cols = []\n",
    "\n",
    "# # Plot Pairplot\n",
    "# display_header(\"Pairplot for Numerical Features\")\n",
    "\n",
    "# sns.pairplot(df[pairplot_cols], hue=\"ATTORNEY\", diag_kind=\"kde\", palette=\"muted\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179445a-301b-40b2-a7f4-856fd8ee4ffe",
   "metadata": {},
   "source": [
    "**Scatterplots for Categorical vs. Numerical Feature Interactions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c900be24-5fde-44f4-8e37-e8ca184a09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scatterplots for Categorical vs. Numerical Features\n",
    "\n",
    "# # Selecting Categorical & Numerical Features for Scatterplots\n",
    "# categorical_features = [\"\"]\n",
    "# numerical_features = [\"\"]\n",
    "\n",
    "# # Creating a Grid of Scatterplots\n",
    "# fig, axes = plt.subplots(len(categorical_features), len(numerical_features), figsize=(15, 12))\n",
    "# fig.suptitle(\"Scatterplots: Categorical vs. Numerical Features\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# # Plot Scatterplots\n",
    "# for i, cat_feature in enumerate(categorical_features):\n",
    "#     for j, num_feature in enumerate(numerical_features):\n",
    "#         sns.scatterplot(data=df, x=num_feature, y=cat_feature, hue=\"ATTORNEY\", alpha=0.7, ax=axes[i, j])\n",
    "#         axes[i, j].set_xlabel(num_feature)\n",
    "#         axes[i, j].set_ylabel(cat_feature)\n",
    "\n",
    "# plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b1bc5f-bceb-4de4-8229-ab31ce42931e",
   "metadata": {},
   "source": [
    "#### **Skewness of Numerical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0e99cbfe-65b6-41f6-8e11-d1417e51091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute Skewness for All Numerical Features\n",
    "# display_header(\"Skewness of Numerical Features :\")\n",
    "# skew_values = df[numerical_columns].skew().reset_index()\n",
    "# skew_values.columns = [\"Columns\", \"Skewness\"]\n",
    "# skew_values[\"Skewness\"] = skew_values[\"Skewness\"].round(2)\n",
    "\n",
    "# # Display Skewness Table Using style_table() Function (Without HTML)\n",
    "# display(style_table(skew_values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b072c-982c-4c36-b864-308936499d97",
   "metadata": {},
   "source": [
    "**Visualizing Skewness (Histograms & KDE Plots)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b2ef61c3-a84b-4ebb-827d-c22e93f86fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Histograms & KDE for Skewness Analysis\n",
    "# display_subheader(\"Skewness Analysis: Histograms & KDE Plots\")\n",
    "\n",
    "# # Calculate the number of rows and columns needed for the subplots\n",
    "# num_cols = 3  # Number of columns in the grid\n",
    "# num_rows = int(np.ceil(len(numerical_columns) / num_cols))  # Calculate the number of rows needed\n",
    "\n",
    "# fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))  # Create the subplots grid\n",
    "# axes = axes.flatten()  # Flatten the axes array for easier iteration\n",
    "\n",
    "# for i, col in enumerate(numerical_columns):\n",
    "#     sns.histplot(df[col], kde=True, ax=axes[i], bins=30, color=\"teal\")\n",
    "#     axes[i].set_title(f\"Distribution of {col}\")\n",
    "\n",
    "# # Hide any extra empty subplots\n",
    "# for j in range(i + 1, len(axes)):\n",
    "#     fig.delaxes(axes[j])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c433d-8b07-4b0c-9d16-47c9995618f2",
   "metadata": {},
   "source": [
    "#### **Handling Missing Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de032b11-3921-4e88-9192-2541ef3fbfad",
   "metadata": {},
   "source": [
    "**Handling Missing Values by Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "20fc16d2-9b8b-43ef-887b-f0a8832ef694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.fillna(df.median(numeric_only=True))\n",
    "# df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d0d52b99-7d7f-4206-a5a4-8cd072483105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb1863-1dca-4b40-8049-cefe0bcf8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=StandardScaler()\n",
    "\n",
    "df_clean=df_clean.drop([\"CASENUM\"], axis=1)\n",
    "pol_type={\"Third-Party\": 1, \"Comprehensive\": 0}\n",
    "drive_rec={\"Clean\": 0, \"Minor Offenses\": 1, \"Major Offenses\": 2}\n",
    "acc_sev={\"Minor\": 0, \"Moderate\": 1, \"Severe\": 2}\n",
    "df_clean[\"Policy_Type\"] = df_clean[\"Policy_Type\"].map(pol_type)\n",
    "df_clean[\"Driving_Record\"] = df_clean[\"Driving_Record\"].map(drive_rec)\n",
    "df_clean[\"Accident_Severity\"] = df_clean[\"Accident_Severity\"].map(acc_sev)\n",
    "# df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c4efe-335c-4932-ae3e-3b24c70612a2",
   "metadata": {},
   "source": [
    "#### **Outlier Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf1b2a-04c5-4e0b-b434-b022a27dd983",
   "metadata": {},
   "source": [
    "**Detect Outliers Using Boxplots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8087d125-d531-4f4c-be2b-fa14c6219c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Only Numerical Columns (Excluding Identifier Columns)\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# # Plot Boxplots for Outlier Detection\n",
    "# display_header(\"Boxplots for Outlier Detection\")\n",
    "\n",
    "# num_features = len(numerical_columns) - 1  # Exclude 'ATTORNEY' (Target Variable)\n",
    "# rows = (num_features // 3) + 1  \n",
    "\n",
    "# fig, axes = plt.subplots(rows, 3, figsize=(15, 5 * rows)) \n",
    "# axes = axes.flatten()  \n",
    "\n",
    "# for i, col in enumerate(numerical_columns):\n",
    "#     if col != \"ATTORNEY\":  # Exclude Target Variable\n",
    "#         sns.boxplot(y=df[col], ax=axes[i], color=\"lightblue\")\n",
    "#         axes[i].set_title(f\"Boxplot of {col}\")\n",
    "\n",
    "# # Hide any extra empty subplots\n",
    "# for j in range(i + 1, len(axes)):\n",
    "#     fig.delaxes(axes[j])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27a7b3-dd89-4df6-b69e-725723315e14",
   "metadata": {},
   "source": [
    "**Implementing IQR for Outlier Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69194a6c-5f1c-4a96-aee9-fd6d06889c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3 style=\"color:#808080; text-align:left;\">Outlier Detection using IQR Method</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply IQR Method for Outlier Detection\n",
    "display_header(\"Outlier Detection using IQR Method\")\n",
    "\n",
    "# Features to Apply IQR Skipping Binary Columns\n",
    "iqr_features = []\n",
    "\n",
    "outlier_counts = {}\n",
    "\n",
    "for col in iqr_features:\n",
    "    Q1 = df[col].quantile(0.25)  # 25th percentile\n",
    "    Q3 = df[col].quantile(0.75)  # 75th percentile\n",
    "    IQR = Q3 - Q1  # Interquartile Range\n",
    "    \n",
    "    # Define Outlier Boundaries\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Count Outliers\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    outlier_counts[col] = len(outliers)\n",
    "\n",
    "# Convert to DataFrame for Display\n",
    "outlier_df = pd.DataFrame(list(outlier_counts.items()), columns=[\"Feature\", \"Outlier Count\"])\n",
    "\n",
    "# Display Outlier Summary Table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c6431124-8874-44f9-a393-e8032a8dc6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove outliers using IQR\n",
    "def remove_outliers(df, columns):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Select only numerical columns for outlier removal\n",
    "num_cols = [\"LOSS\", \"Claim_Amount_Requested\", \"Settlement_Amount\", \"CLMAGE\"]  # Add more if needed\n",
    "df_clean = remove_outliers(df_clean, num_cols)\n",
    "\n",
    "# df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d30a2-b6ae-4d2b-9922-a7b48959ec5b",
   "metadata": {},
   "source": [
    "## **3. Feature Engineering and Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e443a79f-a880-4ca2-b1d0-a1362715f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new calculated columns\n",
    "df_clean[\"set-loss\"] = (df_clean[\"Settlement_Amount\"] - df_clean[\"LOSS\"]) / df_clean[\"Settlement_Amount\"]\n",
    "df_clean[\"claim-loss\"] = (df_clean[\"Claim_Amount_Requested\"] - df_clean[\"LOSS\"]) / df_clean[\"Claim_Amount_Requested\"]\n",
    "df_clean[\"claim-set\"] = (df_clean[\"Claim_Amount_Requested\"] - df_clean[\"Settlement_Amount\"]) / df_clean[\"Claim_Amount_Requested\"]\n",
    "\n",
    "# Drop original columns\n",
    "df_trial1 = df_clean.drop([\"LOSS\", \"Claim_Amount_Requested\", \"Settlement_Amount\"], axis=1)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df_trial1.drop([\"ATTORNEY\"], axis=1)\n",
    "y = df_trial1[\"ATTORNEY\"]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # No reshaping needed\n",
    "\n",
    "# Convert back to DataFrame with correct column names\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "891ca0e0-b976-4398-af9f-2478a37d274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 10))  # Set figure size\n",
    "# sns.heatmap(df_trial1.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "# plt.title(\"Correlation Heatmap\", fontsize=14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b81b7-4ca2-4986-95c1-a50a6b125a18",
   "metadata": {},
   "source": [
    "## **4. Feature Selection & Dimensionality Reduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b36ed4b9-97e6-4e5e-a153-c02f448d8ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to find optimal components\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Compute cumulative explained variance\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# # Plot explained variance\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o')\n",
    "# plt.xlabel(\"Number of Components\")\n",
    "# plt.ylabel(\"Cumulative Explained Variance\")\n",
    "# plt.title(\"Choosing the Optimal Number of PCA Components\")\n",
    "# plt.axhline(y=0.95, color='r', linestyle='--')  # 95% variance threshold\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "016c23ca-e9bb-4a6a-b3c6-0f6c9df787ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components: 10\n"
     ]
    }
   ],
   "source": [
    "# Find the optimal number of components\n",
    "optimal_n = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Optimal number of components: {optimal_n}\")\n",
    "\n",
    "# Apply PCA with optimal components\n",
    "pca = PCA(n_components=optimal_n)\n",
    "principal_components = pca.fit_transform(X_scaled)\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# pca_df = pd.DataFrame(principal_components, columns=[f'PC{i+1}' for i in range(optimal_n)])\n",
    "\n",
    "# # Scatter plot of first two components\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.scatterplot(x=pca_df['PC1'], y=pca_df['PC2'])\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.title('PCA Scatter Plot')\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "\n",
    "# # Explained variance ratio plot\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.plot(range(1, optimal_n + 1), np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "# plt.xlabel(\"Number of Components\")\n",
    "# plt.ylabel(\"Cumulative Explained Variance\")\n",
    "# plt.title(\"Explained Variance vs. Number of Components\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5dd0d-7aa5-4aab-90de-4996400dcaa3",
   "metadata": {},
   "source": [
    "## **5. Model Building & Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ddc08e-12eb-48ad-bc01-8c33b11d549e",
   "metadata": {},
   "source": [
    "**Splitting the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4cba5a57-02b9-43c1-af83-a4eef498fa15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1069, 10), (268, 10), (1069,), (268,))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "x=pca_df\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "27978847-a5c0-4ed6-bde2-3935a1ff538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3 style=\"color:#808080; text-align:left;\">Class Distribution in Train Set</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_163a6 th {\n",
       "  background-color: #2a3f5f;\n",
       "  color: white;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_163a6_row0_col0, #T_163a6_row0_col1, #T_163a6_row1_col0, #T_163a6_row1_col1 {\n",
       "  text-align: left;\n",
       "  border: 1px solid black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_163a6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_163a6_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_163a6_level0_col1\" class=\"col_heading level0 col1\" >Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_163a6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_163a6_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_163a6_row0_col1\" class=\"data row0 col1\" >51.543499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_163a6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_163a6_row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "      <td id=\"T_163a6_row1_col1\" class=\"data row1 col1\" >48.456501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f96e5ca390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3 style=\"color:#808080; text-align:left;\">Class Distribution in Test Set</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e6911 th {\n",
       "  background-color: #2a3f5f;\n",
       "  color: white;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_e6911_row0_col0, #T_e6911_row0_col1, #T_e6911_row1_col0, #T_e6911_row1_col1 {\n",
       "  text-align: left;\n",
       "  border: 1px solid black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e6911\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e6911_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_e6911_level0_col1\" class=\"col_heading level0 col1\" >Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e6911_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e6911_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_e6911_row0_col1\" class=\"data row0 col1\" >50.373134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6911_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e6911_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_e6911_row1_col1\" class=\"data row1 col1\" >49.626866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f96e5ca390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verify the class distribution in both sets\n",
    "train_class_distribution = pd.DataFrame(y_train.value_counts(normalize=True) * 100).reset_index()\n",
    "train_class_distribution.columns = ['Class', 'Percentage']\n",
    "test_class_distribution = pd.DataFrame(y_test.value_counts(normalize=True) * 100).reset_index()\n",
    "test_class_distribution.columns = ['Class', 'Percentage']\n",
    "\n",
    "# Display Class Distributions\n",
    "display_header(\"Class Distribution in Train Set\")\n",
    "display(style_table(train_class_distribution))\n",
    "\n",
    "display_header(\"Class Distribution in Test Set\")\n",
    "display(style_table(test_class_distribution))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c74d94c8-ba8e-4548-b8ea-cb5ba41b7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grids for each model\n",
    "param_grids = {\n",
    "    'xgb': {'n_estimators': [100, 200], 'max_depth': [3, 6], 'learning_rate': [0.01, 0.1]},\n",
    "    'lgb': {'n_estimators': [100, 200], 'max_depth': [3, 6], 'learning_rate': [0.01, 0.1]},\n",
    "    'rf': {'n_estimators': [100, 200], 'max_depth': [None, 10]},\n",
    "    'dt': {'max_depth': [None, 10, 20], 'min_samples_split': [2, 5]},\n",
    "    'lr': {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']},\n",
    "    'svc': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    'knn': {'n_neighbors': [3, 5, 7], 'metric': ['euclidean', 'manhattan']},\n",
    "    'nb': {}  # No hyperparameters for Naive Bayes\n",
    "}\n",
    "\n",
    "# Models dictionary\n",
    "models_dict = {\n",
    "    'xgb': xgb.XGBClassifier(),\n",
    "    'lgb': lgb.LGBMClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'dt': DecisionTreeClassifier(),\n",
    "    'lr': LogisticRegression(),\n",
    "    'svc': SVC(),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'nb': GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1e381869-3577-4ea6-bb36-d4749bdffbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearch for xgb...\n",
      "Best parameters for xgb: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "Running GridSearch for lgb...\n",
      "[LightGBM] [Info] Number of positive: 518, number of negative: 551\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1069, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.484565 -> initscore=-0.061760\n",
      "[LightGBM] [Info] Start training from score -0.061760\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters for lgb: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Running GridSearch for rf...\n",
      "Best parameters for rf: {'max_depth': 10, 'n_estimators': 200}\n",
      "Running GridSearch for dt...\n",
      "Best parameters for dt: {'max_depth': None, 'min_samples_split': 2}\n",
      "Running GridSearch for lr...\n",
      "Best parameters for lr: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Running GridSearch for svc...\n",
      "Best parameters for svc: {'C': 0.1, 'kernel': 'linear'}\n",
      "Running GridSearch for knn...\n",
      "Best parameters for knn: {'metric': 'manhattan', 'n_neighbors': 7}\n",
      "Running GridSearch for nb...\n",
      "Best parameters for nb: {}\n",
      "Best parameters for each model:\n",
      "xgb: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "lgb: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "rf: {'max_depth': 10, 'n_estimators': 200}\n",
      "dt: {'max_depth': None, 'min_samples_split': 2}\n",
      "lr: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "svc: {'C': 0.1, 'kernel': 'linear'}\n",
      "knn: {'metric': 'manhattan', 'n_neighbors': 7}\n",
      "nb: {}\n"
     ]
    }
   ],
   "source": [
    "best_params = {}\n",
    "for name, model in models_dict.items():\n",
    "    print(f\"Running GridSearch for {name}...\")\n",
    "    grid = GridSearchCV(model, param_grids.get(name, {}), cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(x_train, y_train)\n",
    "    best_params[name] = grid.best_params_\n",
    "    print(f\"Best parameters for {name}: {grid.best_params_}\")\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters for each model:\")\n",
    "for model_name, params in best_params.items():\n",
    "    print(f\"{model_name}: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a0e285e7-6e09-4068-b5c0-f51f1c008bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgb': {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200},\n",
       " 'lgb': {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100},\n",
       " 'rf': {'max_depth': 10, 'n_estimators': 200},\n",
       " 'dt': {'max_depth': None, 'min_samples_split': 2},\n",
       " 'lr': {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       " 'svc': {'C': 0.1, 'kernel': 'linear'},\n",
       " 'knn': {'metric': 'manhattan', 'n_neighbors': 7},\n",
       " 'nb': {}}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fbec3d0a-651c-47dc-8596-8bf5456725eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBClassifier(**best_params['xgb'])\n",
    "model_lgb = lgb.LGBMClassifier(**best_params['lgb'])\n",
    "model_rf = RandomForestClassifier(**best_params['rf'])\n",
    "model_dt = DecisionTreeClassifier(**best_params['dt'])\n",
    "model_lr = LogisticRegression(**best_params['lr'])\n",
    "model_svc = SVC(**best_params['svc'])\n",
    "model_knn = KNeighborsClassifier(**best_params['knn'])\n",
    "model_nb = GaussianNB()  # No params needed\n",
    "models=[model_xgb,model_lgb,model_rf,model_dt,model_lr,model_svc,model_knn,model_nb]\n",
    "model_names = ['XGBoost', 'LightGBM', 'RandomForest', 'DecisionTree',\n",
    "               'LogisticRegression', 'SVC', 'KNN', 'NaiveBayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "668ea8e4-f7c9-4e35-88c3-0efa6b394f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Evaluating XGBoost...\n",
      "Training and Evaluating LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 518, number of negative: 551\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1069, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.484565 -> initscore=-0.061760\n",
      "[LightGBM] [Info] Start training from score -0.061760\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training and Evaluating RandomForest...\n",
      "Training and Evaluating DecisionTree...\n",
      "Training and Evaluating LogisticRegression...\n",
      "Training and Evaluating SVC...\n",
      "Training and Evaluating KNN...\n",
      "Training and Evaluating NaiveBayes...\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in zip(model_names, models):\n",
    "    print(f\"Training and Evaluating {name}...\")\n",
    "    \n",
    "    # Fit the model on training data\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results.append([name, accuracy, precision, recall, f1])\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# # Print the results table\n",
    "# print(results_df)\n",
    "\n",
    "# # Optionally, display as a sorted table by F1 Score\n",
    "# results_df = results_df.sort_values(by='F1 Score', ascending=False)\n",
    "# print(\"\\nSorted Results by F1 Score:\")\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dcb12a0d-c2df-4ffb-b553-3d44b9872dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6b3c3988-70cb-4179-97dc-6bd1c8527717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prathamesh\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5197 - loss: 0.7014 - val_accuracy: 0.4963 - val_loss: 0.6904\n",
      "Epoch 2/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5342 - loss: 0.6898 - val_accuracy: 0.5224 - val_loss: 0.6894\n",
      "Epoch 3/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5519 - loss: 0.6864 - val_accuracy: 0.5261 - val_loss: 0.6885\n",
      "Epoch 4/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5428 - loss: 0.6801 - val_accuracy: 0.5112 - val_loss: 0.6879\n",
      "Epoch 5/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5836 - loss: 0.6775 - val_accuracy: 0.5224 - val_loss: 0.6884\n",
      "Epoch 6/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5501 - loss: 0.6793 - val_accuracy: 0.5299 - val_loss: 0.6885\n",
      "Epoch 7/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5837 - loss: 0.6830 - val_accuracy: 0.5410 - val_loss: 0.6897\n",
      "Epoch 8/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5790 - loss: 0.6754 - val_accuracy: 0.5448 - val_loss: 0.6898\n",
      "Epoch 9/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5837 - loss: 0.6776 - val_accuracy: 0.5410 - val_loss: 0.6904\n",
      "Epoch 10/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5760 - loss: 0.6722 - val_accuracy: 0.5410 - val_loss: 0.6900\n",
      "Epoch 11/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5474 - loss: 0.6784 - val_accuracy: 0.5448 - val_loss: 0.6900\n",
      "Epoch 12/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5635 - loss: 0.6772 - val_accuracy: 0.5261 - val_loss: 0.6906\n",
      "Epoch 13/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5821 - loss: 0.6721 - val_accuracy: 0.5261 - val_loss: 0.6915\n",
      "Epoch 14/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5597 - loss: 0.6749 - val_accuracy: 0.5261 - val_loss: 0.6915\n",
      "Epoch 15/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5698 - loss: 0.6742 - val_accuracy: 0.5336 - val_loss: 0.6901\n",
      "Epoch 16/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5845 - loss: 0.6701 - val_accuracy: 0.5224 - val_loss: 0.6907\n",
      "Epoch 17/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5933 - loss: 0.6697 - val_accuracy: 0.5448 - val_loss: 0.6928\n",
      "Epoch 18/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5924 - loss: 0.6682 - val_accuracy: 0.5410 - val_loss: 0.6926\n",
      "Epoch 19/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5782 - loss: 0.6675 - val_accuracy: 0.5299 - val_loss: 0.6943\n",
      "Epoch 20/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6062 - loss: 0.6706 - val_accuracy: 0.5224 - val_loss: 0.6947\n",
      "Epoch 21/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6085 - loss: 0.6569 - val_accuracy: 0.5373 - val_loss: 0.6959\n",
      "Epoch 22/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6087 - loss: 0.6607 - val_accuracy: 0.5336 - val_loss: 0.6974\n",
      "Epoch 23/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6312 - loss: 0.6598 - val_accuracy: 0.5187 - val_loss: 0.6979\n",
      "Epoch 24/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6081 - loss: 0.6580 - val_accuracy: 0.5410 - val_loss: 0.6999\n",
      "Epoch 25/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5942 - loss: 0.6685 - val_accuracy: 0.5261 - val_loss: 0.7003\n",
      "Epoch 26/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6072 - loss: 0.6594 - val_accuracy: 0.5261 - val_loss: 0.7022\n",
      "Epoch 27/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5912 - loss: 0.6673 - val_accuracy: 0.5299 - val_loss: 0.7033\n",
      "Epoch 28/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5781 - loss: 0.6754 - val_accuracy: 0.5410 - val_loss: 0.7016\n",
      "Epoch 29/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6142 - loss: 0.6590 - val_accuracy: 0.5187 - val_loss: 0.7044\n",
      "Epoch 30/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5944 - loss: 0.6587 - val_accuracy: 0.4851 - val_loss: 0.7061\n",
      "Epoch 31/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5887 - loss: 0.6619 - val_accuracy: 0.5261 - val_loss: 0.7063\n",
      "Epoch 32/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6141 - loss: 0.6599 - val_accuracy: 0.5149 - val_loss: 0.7063\n",
      "Epoch 33/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6164 - loss: 0.6480 - val_accuracy: 0.5336 - val_loss: 0.7085\n",
      "Epoch 34/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6317 - loss: 0.6470 - val_accuracy: 0.5149 - val_loss: 0.7102\n",
      "Epoch 35/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6251 - loss: 0.6474 - val_accuracy: 0.5149 - val_loss: 0.7119\n",
      "Epoch 36/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6348 - loss: 0.6444 - val_accuracy: 0.4888 - val_loss: 0.7147\n",
      "Epoch 37/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6266 - loss: 0.6482 - val_accuracy: 0.5000 - val_loss: 0.7135\n",
      "Epoch 38/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6093 - loss: 0.6576 - val_accuracy: 0.4925 - val_loss: 0.7149\n",
      "Epoch 39/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6373 - loss: 0.6425 - val_accuracy: 0.5112 - val_loss: 0.7180\n",
      "Epoch 40/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6270 - loss: 0.6532 - val_accuracy: 0.4739 - val_loss: 0.7194\n",
      "Epoch 41/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6229 - loss: 0.6430 - val_accuracy: 0.4888 - val_loss: 0.7198\n",
      "Epoch 42/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6400 - loss: 0.6391 - val_accuracy: 0.4813 - val_loss: 0.7204\n",
      "Epoch 43/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6058 - loss: 0.6551 - val_accuracy: 0.4776 - val_loss: 0.7195\n",
      "Epoch 44/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6274 - loss: 0.6384 - val_accuracy: 0.4739 - val_loss: 0.7212\n",
      "Epoch 45/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6179 - loss: 0.6464 - val_accuracy: 0.4776 - val_loss: 0.7231\n",
      "Epoch 46/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6168 - loss: 0.6452 - val_accuracy: 0.4888 - val_loss: 0.7225\n",
      "Epoch 47/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6736 - loss: 0.6219 - val_accuracy: 0.4888 - val_loss: 0.7286\n",
      "Epoch 48/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6186 - loss: 0.6547 - val_accuracy: 0.4701 - val_loss: 0.7299\n",
      "Epoch 49/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6368 - loss: 0.6293 - val_accuracy: 0.4888 - val_loss: 0.7306\n",
      "Epoch 50/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6528 - loss: 0.6259 - val_accuracy: 0.4776 - val_loss: 0.7371\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Define the neural network model\n",
    "def create_nn():\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "model_nn = create_nn()\n",
    "history = model_nn.fit(x_train_scaled, y_train, \n",
    "                       validation_data=(x_test_scaled, y_test),\n",
    "                       epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_nn = (model_nn.predict(x_test_scaled) > 0.5).astype(int)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_nn)\n",
    "precision = precision_score(y_test, y_pred_nn)\n",
    "recall = recall_score(y_test, y_pred_nn)\n",
    "f1 = f1_score(y_test, y_pred_nn)\n",
    "\n",
    "# Print results\n",
    "# print(f\"Neural Network Performance:\\nAccuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fcc31fc0-0ca8-4fb5-8668-e60efdba4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Neural Network results to results_df\n",
    "nn_results = pd.DataFrame([[\"Neural Network\", 0.5037, 0.5085, 0.4444, 0.4743]], \n",
    "                          columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results_df = pd.concat([results_df, nn_results], ignore_index=True)\n",
    "\n",
    "# # Print updated results\n",
    "# print(\"\\nUpdated Results with Neural Network:\")\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d06abb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Get predicted probabilities\n",
    "# y_prob = model.predict_proba(x_test)[:, 1]  # Probability for class 1\n",
    "\n",
    "# # Calculate FPR, TPR, and threshold values\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# # Compute ROC-AUC score\n",
    "# roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "# # Plot the curve\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\", color='blue')\n",
    "# plt.plot([0, 1], [0, 1], linestyle=\"--\", color='grey')  # Diagonal line\n",
    "# plt.xlabel(\"False Positive Rate\")\n",
    "# plt.ylabel(\"True Positive Rate\")\n",
    "# plt.title(\"ROC-AUC Curve\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "52e57366-2788-42bd-ac34-58c9a937d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Set positions for bars\n",
    "# x = np.arange(len(results_df['Model']))\n",
    "\n",
    "# # Define width of bars\n",
    "# bar_width = 0.2\n",
    "\n",
    "# # Plot bars for each metric\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(x - 1.5 * bar_width, results_df['Accuracy'], width=bar_width, label='Accuracy', color='blue')\n",
    "# plt.bar(x - 0.5 * bar_width, results_df['Precision'], width=bar_width, label='Precision', color='green')\n",
    "# plt.bar(x + 0.5 * bar_width, results_df['Recall'], width=bar_width, label='Recall', color='orange')\n",
    "# plt.bar(x + 1.5 * bar_width, results_df['F1 Score'], width=bar_width, label='F1 Score', color='red')\n",
    "\n",
    "# # Set labels and title\n",
    "# plt.xlabel('Models')\n",
    "# plt.ylabel('Scores')\n",
    "# plt.title('Model Performance Comparison')\n",
    "# plt.xticks(ticks=x, labels=results_df['Model'], rotation=45)\n",
    "# plt.legend()\n",
    "\n",
    "# # Show plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ce46d8dd-d20f-4378-8f24-cf4359fb398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# # Assuming `logistic_regression_model` is your trained model\n",
    "# joblib.dump(model_lr, 'best_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe5aead-33d7-44eb-af32-379006f8a636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115e0bc-48ee-4e55-98af-f969610556a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
